# 每日从arXiv中获取最新YOLO相关论文


## Effective Defect Detection Using Instance Segmentation for NDI / 

发布日期：2025-01-24

作者：Ashiqur Rahman

摘要：Ultrasonic testing is a common Non\-Destructive Inspection \(NDI\) method used in aerospace manufacturing. However, the complexity and size of the ultrasonic scans make it challenging to identify defects through visual inspection or machine learning models. Using computer vision techniques to identify defects from ultrasonic scans is an evolving research area. In this study, we used instance segmentation to identify the presence of defects in the ultrasonic scan images of composite panels that are representative of real components manufactured in aerospace. We used two models based on Mask\-RCNN \(Detectron 2\) and YOLO 11 respectively. Additionally, we implemented a simple statistical pre\-processing technique that reduces the burden of requiring custom\-tailored pre\-processing techniques. Our study demonstrates the feasibility and effectiveness of using instance segmentation in the NDI pipeline by significantly reducing data pre\-processing time, inspection time, and overall costs.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2501.14149v1)

---


## YOLOv8 to YOLO11: A Comprehensive Architecture In\-depth Comparative Review / 

发布日期：2025-01-23

作者：Priyanto Hidayatullah

摘要：In the field of deep learning\-based computer vision, YOLO is revolutionary. With respect to deep learning models, YOLO is also the one that is evolving the most rapidly. Unfortunately, not every YOLO model possesses scholarly publications. Moreover, there exists a YOLO model that lacks a publicly accessible official architectural diagram. Naturally, this engenders challenges, such as complicating the understanding of how the model operates in practice. Furthermore, the review articles that are presently available do not delve into the specifics of each model. The objective of this study is to present a comprehensive and in\-depth architecture comparison of the four most recent YOLO models, specifically YOLOv8 through YOLO11, thereby enabling readers to quickly grasp not only how each model functions, but also the distinctions between them. To analyze each YOLO version's architecture, we meticulously examined the relevant academic papers, documentation, and scrutinized the source code. The analysis reveals that while each version of YOLO has improvements in architecture and feature extraction, certain blocks remain unchanged. The lack of scholarly publications and official diagrams presents challenges for understanding the model's functionality and future enhancement. Future developers are encouraged to provide these resources.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2501.13400v1)

---


## Enhanced PEC\-YOLO for Detecting Improper Safety Gear Wearing Among Power Line Workers / 

发布日期：2025-01-23

作者：Chen Zuguo

摘要：To address the high risks associated with improper use of safety gear in complex power line environments, where target occlusion and large variance are prevalent, this paper proposes an enhanced PEC\-YOLO object detection algorithm. The method integrates deep perception with multi\-scale feature fusion, utilizing PConv and EMA attention mechanisms to enhance feature extraction efficiency and minimize model complexity. The CPCA attention mechanism is incorporated into the SPPF module, improving the model's ability to focus on critical information and enhance detection accuracy, particularly in challenging conditions. Furthermore, the introduction of the BiFPN neck architecture optimizes the utilization of low\-level and high\-level features, enhancing feature representation through adaptive fusion and context\-aware mechanism. Experimental results demonstrate that the proposed PEC\-YOLO achieves a 2.7% improvement in detection accuracy compared to YOLOv8s, while reducing model parameters by 42.58%. Under identical conditions, PEC\-YOLO outperforms other models in detection speed, meeting the stringent accuracy requirements for safety gear detection in construction sites. This study contributes to the development of efficient and accurate intelligent monitoring systems for ensuring worker safety in hazardous environments.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2501.13981v1)

---


## YOLOSCM: An improved YOLO algorithm for cars detection / 

发布日期：2025-01-23

作者：Changhui Deng

摘要：Detecting objects in urban traffic images presents considerable difficulties because of the following reasons: 1\) These images are typically immense in size, encompassing millions or even hundreds of millions of pixels, yet computational resources are constrained. 2\) The small size of vehicles in certain scenarios leads to insufficient information for accurate detection. 3\) The uneven distribution of vehicles causes inefficient use of computational resources. To address these issues, we propose YOLOSCM \(You Only Look Once with Segmentation Clustering Module\), an efficient and effective framework. To address the challenges of large\-scale images and the non\-uniform distribution of vehicles, we propose a Segmentation Clustering Module \(SCM\). This module adaptively identifies clustered regions, enabling the model to focus on these areas for more precise detection. Additionally, we propose a new training strategy to optimize the detection of small vehicles and densely packed targets in complex urban traffic scenes. We perform extensive experiments on urban traffic datasets to demonstrate the effectiveness and superiority of our proposed approach.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2501.13343v1)

---


## LiCAR: pseudo\-RGB LiDAR image for CAR segmentation / 

发布日期：2025-01-21

作者：Ignacio de Loyola Páez\-Ubieta

摘要：With the advancement of computing resources, an increasing number of Neural Networks \(NNs\) are appearing for image detection and segmentation appear. However, these methods usually accept as input a RGB 2D image. On the other side, Light Detection And Ranging \(LiDAR\) sensors with many layers provide images that are similar to those obtained from a traditional low resolution RGB camera. Following this principle, a new dataset for segmenting cars in pseudo\-RGB images has been generated. This dataset combines the information given by the LiDAR sensor into a Spherical Range Image \(SRI\), concretely the reflectivity, near infrared and signal intensity 2D images. These images are then fed into instance segmentation NNs. These NNs segment the cars that appear in these images, having as result a Bounding Box \(BB\) and mask precision of 88% and 81.5% respectively with You Only Look Once \(YOLO\)\-v8 large. By using this segmentation NN, some trackers have been applied so as to follow each car segmented instance along a video feed, having great performance in real world experiments.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2501.13960v1)

---

