# 每日从arXiv中获取最新YOLO相关论文


## Drone\-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms / 

发布日期：2025-09-12

作者：Mohammadreza Narimani

摘要：This study addresses the escalating threat of branched broomrape \(Phelipanche ramosa\) to California's tomato industry, which supplies over 90 percent of U.S. processing tomatoes. The parasite's largely underground life cycle makes early detection difficult, while conventional chemical controls are costly, environmentally harmful, and often ineffective. To address this, we combined drone\-based multispectral imagery with Long Short\-Term Memory \(LSTM\) deep learning networks, using the Synthetic Minority Over\-sampling Technique \(SMOTE\) to handle class imbalance. Research was conducted on a known broomrape\-infested tomato farm in Woodland, Yolo County, CA, across five key growth stages determined by growing degree days \(GDD\). Multispectral images were processed to isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with 79.09 percent overall accuracy and 70.36 percent recall without integrating later stages. Incorporating sequential growth stages with LSTM improved detection substantially. The best\-performing scenario, which integrated all growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy and 95.37 percent recall. These results demonstrate the strong potential of temporal multispectral analysis and LSTM networks for early broomrape detection. While further real\-world data collection is needed for practical deployment, this study shows that UAV\-based multispectral sensing coupled with deep learning could provide a powerful precision agriculture tool to reduce losses and improve sustainability in tomato production.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09972v1)

---


## Zero\-Shot Referring Expression Comprehension via Visual\-Language True/False Verification / 

发布日期：2025-09-12

作者：Jeffrey Liu

摘要：Referring Expression Comprehension \(REC\) is usually addressed with task\-trained grounding models. We show that a zero\-shot workflow, without any REC\-specific training, can achieve competitive or superior performance. Our approach reformulates REC as box\-wise visual\-language verification: given proposals from a COCO\-clean generic detector \(YOLO\-World\), a general\-purpose VLM independently answers True/False queries for each region. This simple procedure reduces cross\-box interference, supports abstention and multiple matches, and requires no fine\-tuning. On RefCOCO, RefCOCO\+, and RefCOCOg, our method not only surpasses a zero\-shot GroundingDINO baseline but also exceeds reported results for GroundingDINO trained on REC and GroundingDINO\+CRG. Controlled studies with identical proposals confirm that verification significantly outperforms selection\-based prompting, and results hold with open VLMs. Overall, we show that workflow design, rather than task\-specific pretraining, drives strong zero\-shot REC performance.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09958v1)

---


## A Co\-Training Semi\-Supervised Framework Using Faster R\-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images / 

发布日期：2025-09-11

作者：Hossein Yazdanjouei

摘要：This study proposes a semi\-supervised co\-training framework for object detection in densely packed retail environments, where limited labeled data and complex conditions pose major challenges. The framework combines Faster R\-CNN \(utilizing a ResNet backbone\) for precise localization with YOLO \(employing a Darknet backbone\) for global context, enabling mutual pseudo\-label exchange that improves accuracy in scenes with occlusion and overlapping objects. To strengthen classification, it employs an ensemble of XGBoost, Random Forest, and SVM, utilizing diverse feature representations for higher robustness. Hyperparameters are optimized using a metaheuristic\-driven algorithm, enhancing precision and efficiency across models. By minimizing reliance on manual labeling, the approach reduces annotation costs and adapts effectively to frequent product and layout changes common in retail. Experiments on the SKU\-110k dataset demonstrate strong performance, highlighting the scalability and practicality of the proposed framework for real\-world retail applications such as automated inventory tracking, product monitoring, and checkout systems.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09750v1)

---


## Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles / 

发布日期：2025-09-11

作者：Ian Nell

摘要：Road traffic accidents remain a significant global concern, with human error, particularly distracted and impaired driving, among the leading causes. This study introduces a novel driver behavior classification system that uses external observation techniques to detect indicators of distraction and impairment. The proposed framework employs advanced computer vision methodologies, including real\-time object tracking, lateral displacement analysis, and lane position monitoring. The system identifies unsafe driving behaviors such as excessive lateral movement and erratic trajectory patterns by implementing the YOLO object detection model and custom lane estimation algorithms. Unlike systems reliant on inter\-vehicular communication, this vision\-based approach enables behavioral analysis of non\-connected vehicles. Experimental evaluations on diverse video datasets demonstrate the framework's reliability and adaptability across varying road and environmental conditions.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09349v1)

---


## Model\-Agnostic Open\-Set Air\-to\-Air Visual Object Detection for Reliable UAV Perception / 

发布日期：2025-09-11

作者：Spyridon Loukovitis

摘要：Open\-set detection is crucial for robust UAV autonomy in air\-to\-air object detection under real\-world conditions. Traditional closed\-set detectors degrade significantly under domain shifts and flight data corruption, posing risks to safety\-critical applications. We propose a novel, model\-agnostic open\-set detection framework designed specifically for embedding\-based detectors. The method explicitly handles unknown object rejection while maintaining robustness against corrupted flight data. It estimates semantic uncertainty via entropy modeling in the embedding space and incorporates spectral normalization and temperature scaling to enhance open\-set discrimination. We validate our approach on the challenging AOT aerial benchmark and through extensive real\-world flight tests. Comprehensive ablation studies demonstrate consistent improvements over baseline methods, achieving up to a 10% relative AUROC gain compared to standard YOLO\-based detectors. Additionally, we show that background rejection further strengthens robustness without compromising detection accuracy, making our solution particularly well\-suited for reliable UAV perception in dynamic air\-to\-air environments.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09297v1)

---

