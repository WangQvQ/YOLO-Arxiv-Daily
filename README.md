# 每日从arXiv中获取最新YOLO相关论文


## YOLO\-CIANNA: Galaxy detection with deep learning in radio data: II. Winning the SKA SDC2 using a generalized 3D\-YOLO network / 

发布日期：2025-09-15

作者：D. Cornu

摘要：As the scientific exploitation of the Square Kilometre Array \(SKA\) approaches, there is a need for new advanced data analysis and visualization tools capable of processing large high\-dimensional datasets. In this study, we aim to generalize the YOLO\-CIANNA deep learning source detection and characterization method for 3D hyperspectral HI emission cubes. We present the adaptations we made to the regression\-based detection formalism and the construction of an end\-to\-end 3D convolutional neural network \(CNN\) backbone. We then describe a processing pipeline for applying the method to simulated 3D HI cubes from the SKA Observatory Science Data Challenge 2 \(SDC2\) dataset. The YOLO\-CIANNA method was originally developed and used by the MINERVA team that won the official SDC2 competition. Despite the public release of the full SDC2 dataset, no published result has yet surpassed MINERVA's top score. In this paper, we present an updated version of our method that improves our challenge score by 9.5%. The resulting catalog exhibits a high detection purity of 92.3%, best\-in\-class characterization accuracy, and contains 45% more confirmed sources than concurrent classical detection tools. The method is also computationally efficient, processing the full ~1TB SDC2 data cube in 30 min on a single GPU. These state\-of\-the\-art results highlight the effectiveness of 3D CNN\-based detectors for processing large hyperspectral data cubes and represent a promising step toward applying YOLO\-CIANNA to observational data from SKA and its precursors.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.12082v1)

---


## Drone\-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms / 

发布日期：2025-09-12

作者：Mohammadreza Narimani

摘要：This study addresses the escalating threat of branched broomrape \(Phelipanche ramosa\) to California's tomato industry, which supplies over 90 percent of U.S. processing tomatoes. The parasite's largely underground life cycle makes early detection difficult, while conventional chemical controls are costly, environmentally harmful, and often ineffective. To address this, we combined drone\-based multispectral imagery with Long Short\-Term Memory \(LSTM\) deep learning networks, using the Synthetic Minority Over\-sampling Technique \(SMOTE\) to handle class imbalance. Research was conducted on a known broomrape\-infested tomato farm in Woodland, Yolo County, CA, across five key growth stages determined by growing degree days \(GDD\). Multispectral images were processed to isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with 79.09 percent overall accuracy and 70.36 percent recall without integrating later stages. Incorporating sequential growth stages with LSTM improved detection substantially. The best\-performing scenario, which integrated all growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy and 95.37 percent recall. These results demonstrate the strong potential of temporal multispectral analysis and LSTM networks for early broomrape detection. While further real\-world data collection is needed for practical deployment, this study shows that UAV\-based multispectral sensing coupled with deep learning could provide a powerful precision agriculture tool to reduce losses and improve sustainability in tomato production.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09972v1)

---


## Zero\-Shot Referring Expression Comprehension via Visual\-Language True/False Verification / 

发布日期：2025-09-12

作者：Jeffrey Liu

摘要：Referring Expression Comprehension \(REC\) is usually addressed with task\-trained grounding models. We show that a zero\-shot workflow, without any REC\-specific training, can achieve competitive or superior performance. Our approach reformulates REC as box\-wise visual\-language verification: given proposals from a COCO\-clean generic detector \(YOLO\-World\), a general\-purpose VLM independently answers True/False queries for each region. This simple procedure reduces cross\-box interference, supports abstention and multiple matches, and requires no fine\-tuning. On RefCOCO, RefCOCO\+, and RefCOCOg, our method not only surpasses a zero\-shot GroundingDINO baseline but also exceeds reported results for GroundingDINO trained on REC and GroundingDINO\+CRG. Controlled studies with identical proposals confirm that verification significantly outperforms selection\-based prompting, and results hold with open VLMs. Overall, we show that workflow design, rather than task\-specific pretraining, drives strong zero\-shot REC performance.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09958v1)

---


## A Co\-Training Semi\-Supervised Framework Using Faster R\-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images / 

发布日期：2025-09-11

作者：Hossein Yazdanjouei

摘要：This study proposes a semi\-supervised co\-training framework for object detection in densely packed retail environments, where limited labeled data and complex conditions pose major challenges. The framework combines Faster R\-CNN \(utilizing a ResNet backbone\) for precise localization with YOLO \(employing a Darknet backbone\) for global context, enabling mutual pseudo\-label exchange that improves accuracy in scenes with occlusion and overlapping objects. To strengthen classification, it employs an ensemble of XGBoost, Random Forest, and SVM, utilizing diverse feature representations for higher robustness. Hyperparameters are optimized using a metaheuristic\-driven algorithm, enhancing precision and efficiency across models. By minimizing reliance on manual labeling, the approach reduces annotation costs and adapts effectively to frequent product and layout changes common in retail. Experiments on the SKU\-110k dataset demonstrate strong performance, highlighting the scalability and practicality of the proposed framework for real\-world retail applications such as automated inventory tracking, product monitoring, and checkout systems.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09750v1)

---


## Classification of Driver Behaviour Using External Observation Techniques for Autonomous Vehicles / 

发布日期：2025-09-11

作者：Ian Nell

摘要：Road traffic accidents remain a significant global concern, with human error, particularly distracted and impaired driving, among the leading causes. This study introduces a novel driver behavior classification system that uses external observation techniques to detect indicators of distraction and impairment. The proposed framework employs advanced computer vision methodologies, including real\-time object tracking, lateral displacement analysis, and lane position monitoring. The system identifies unsafe driving behaviors such as excessive lateral movement and erratic trajectory patterns by implementing the YOLO object detection model and custom lane estimation algorithms. Unlike systems reliant on inter\-vehicular communication, this vision\-based approach enables behavioral analysis of non\-connected vehicles. Experimental evaluations on diverse video datasets demonstrate the framework's reliability and adaptability across varying road and environmental conditions.

中文摘要：


代码链接：摘要中未找到代码链接。

论文链接：[阅读更多](http://arxiv.org/abs/2509.09349v1)

---

